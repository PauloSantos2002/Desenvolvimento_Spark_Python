{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkRhLRQ0Nx35/WCN5TZMM/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PauloSantos2002/Desenvolvimento_Spark_Python/blob/main/SparkPytonFaculdade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "i_YNc5_8onL9"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6hk4U02OtLB",
        "outputId": "0d3909a8-7f76-4537-af8b-7ac201f5435d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<SparkContext master=local[*] appName=TesteInstalacaoSpark>\n",
            "3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#usando SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()#criando uma sessão\n",
        "print(spark)\n",
        "print(\"-----------\")\n",
        "dataset = spark.read.csv('/content/sample_data/california_housing_test.csv',inferSchema=True,header=True)\n",
        "dataset.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4kvLGO9TTys",
        "outputId": "9b21ad5b-9445-43f4-b7ed-cdfefbcef0e4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pyspark.sql.session.SparkSession object at 0x7a129d54b440>\n",
            "-----------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#criar uma tabela SQL temporária com os dados do “dataset”\n",
        "dataset.createOrReplaceTempView('tabela_temporaria')\n",
        "print(spark.catalog.listTables())\n",
        "print(\"-----------\")\n",
        "\n",
        "#consulta SQL\n",
        "query = 'FROM tabela_temporaria SELECT longitude, latitude LIMIT 3'\n",
        "saida = spark.sql(query)\n",
        "saida.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ0it5tQUqjE",
        "outputId": "193fa7fe-6854-40eb-f885-e00566f94255"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Table(name='tabela_temporaria', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n",
            "-----------\n",
            "+---------+--------+\n",
            "|longitude|latitude|\n",
            "+---------+--------+\n",
            "|  -122.05|   37.37|\n",
            "|   -118.3|   34.26|\n",
            "|  -117.81|   33.78|\n",
            "+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Converter Spark SQL para Pandas**\n",
        "\n",
        "\n",
        "*   Implementar a consulta SQL na tabela “tabela_temporaria” que já carregamos no Spark para retornar a quantidade máxima de quartos\n",
        "*   Executar a consulta SQL no Spark e, assim, obter um DataFrame do Spar\n",
        "*   Converter o resultado da etapa anterior para um DataFrame do Pandas.\n",
        "*   Imprimir o resultado da consulta.\n",
        "*   Converter o valor do DataFrame para um valor inteiro.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jLRNugsjWh_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = 'SELECT MAX(total_rooms) as maximo_quartos FROM tabela_temporaria'\n",
        "q_maximo_quartos = spark.sql(query1)\n",
        "pd_maximo_quartos = q_maximo_quartos.toPandas()\n",
        "print('A quantidade máxima de quartos é: {}'.format(pd_maximo_quartos['maximo_quartos']))\n",
        "qtd_maximo_quartos = int(pd_maximo_quartos.loc[0,'maximo_quartos'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC9gZpYRXM2Z",
        "outputId": "fd2826f3-4d47-4656-f026-39154c3e9031"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A quantidade máxima de quartos é: 0    30450.0\n",
            "Name: maximo_quartos, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wXG5C0ZkXMi5"
      }
    }
  ]
}