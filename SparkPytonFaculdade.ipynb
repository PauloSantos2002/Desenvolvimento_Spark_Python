{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORIlKyoFw88XZU6zoHRKnP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PauloSantos2002/Desenvolvimento_Spark_Python/blob/main/SparkPytonFaculdade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i_YNc5_8onL9"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "spark_contexto = SparkContext()\n",
        "print(spark_contexto)\n",
        "print(spark_contexto.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcz2ch7Zb8zu",
        "outputId": "d1b4bbeb-b943-4666-96c7-69b54bce6647"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<SparkContext master=local[*] appName=pyspark-shell>\n",
            "3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#usando SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()#criando uma sessão\n",
        "print(spark)\n",
        "print(\"-----------\")\n",
        "dataset = spark.read.csv('/content/sample_data/california_housing_test.csv',inferSchema=True,header=True)\n",
        "dataset.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4kvLGO9TTys",
        "outputId": "7a0ee985-76be-48ed-9b51-713ee0c99e66"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pyspark.sql.session.SparkSession object at 0x7c5f96d5e630>\n",
            "-----------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#criar uma tabela SQL temporária com os dados do “dataset”\n",
        "dataset.createOrReplaceTempView('tabela_temporaria')\n",
        "print(spark.catalog.listTables())\n",
        "print(\"-----------\")\n",
        "\n",
        "#consulta SQL\n",
        "query = 'FROM tabela_temporaria SELECT longitude, latitude LIMIT 3'\n",
        "saida = spark.sql(query)\n",
        "saida.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ0it5tQUqjE",
        "outputId": "00dcd7f3-9266-42e1-b067-b770e621a9e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Table(name='tabela_temporaria', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n",
            "-----------\n",
            "+---------+--------+\n",
            "|longitude|latitude|\n",
            "+---------+--------+\n",
            "|  -122.05|   37.37|\n",
            "|   -118.3|   34.26|\n",
            "|  -117.81|   33.78|\n",
            "+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Converter Spark SQL para Pandas**\n",
        "\n",
        "\n",
        "*   Implementar a consulta SQL na tabela “tabela_temporaria” que já carregamos no Spark para retornar a quantidade máxima de quartos\n",
        "*   Executar a consulta SQL no Spark e, assim, obter um DataFrame do Spar\n",
        "*   Converter o resultado da etapa anterior para um DataFrame do Pandas.\n",
        "*   Imprimir o resultado da consulta.\n",
        "*   Converter o valor do DataFrame para um valor inteiro.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jLRNugsjWh_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = 'SELECT MAX(total_rooms) as maximo_quartos FROM tabela_temporaria'\n",
        "q_maximo_quartos = spark.sql(query1)\n",
        "pd_maximo_quartos = q_maximo_quartos.toPandas()\n",
        "print('A quantidade máxima de quartos é: {}'.format(pd_maximo_quartos['maximo_quartos']))\n",
        "qtd_maximo_quartos = int(pd_maximo_quartos.loc[0,'maximo_quartos'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC9gZpYRXM2Z",
        "outputId": "7c489436-fb72-41b2-d6f8-ef5523d2f40f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A quantidade máxima de quartos é: 0    30450.0\n",
            "Name: maximo_quartos, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = 'SELECT longitude, latitude FROM tabela_temporaria WHERE total_rooms = '+str(qtd_maximo_quartos)\n",
        "\n",
        "localizacao_maximo_quartos = spark.sql(query2)\n",
        "\n",
        "pd_localizacao_maximo_quartos = localizacao_maximo_quartos.toPandas()\n",
        "print(pd_localizacao_maximo_quartos.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojH1qGANafjI",
        "outputId": "6d76fd35-a0c3-4119-a79a-43a4063bdbd3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   longitude  latitude\n",
            "0     -117.2     33.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converter Pandas DataFrame para Spark **DataFrame**\n",
        "\n",
        "\n",
        "\n",
        "*   Geração de dados aleatórios que seguem a distribuição normal com média e desvio-padrão que nós fornecemos. Usamos a biblioteca Numpy para gerar os dados e a Pandas para organizá-los em um DataFrame.\n",
        "*   Converter o DataFrame do Pandas para um DataFrame do Spark.\n",
        "*   Imprimir a lista de tabelas no catálogo do Spark.\n",
        "*   Adicionar a tabela temporária no catálogo do Spark.\n",
        "*   Examinar as tabelas no catálogo do Spark novamente.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AETv1kLpa3Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "media = 0\n",
        "desvio_padrao=0.1\n",
        "pd_temporario = pd.DataFrame(np.random.normal(media,desvio_padrao,100))\n",
        "spark_temporario = spark.createDataFrame(pd_temporario)\n",
        "\n",
        "print(spark.catalog.listTables())\n",
        "spark_temporario.createOrReplaceTempView('nova_tabela_temporaria')\n",
        "\n",
        "print(spark.catalog.listTables())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O6O0ignbYin",
        "outputId": "591ca486-ebf9-48f8-ddaf-a7ade5f9d3d6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Table(name='tabela_temporaria', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n",
            "[Table(name='nova_tabela_temporaria', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True), Table(name='tabela_temporaria', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "uta1FQsUfK8N"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}